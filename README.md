# Tunisian-Dialect-Toxicity-Detection-using-Fine_Tuned_Bert
### README for Tunisian-Dialect-Toxicity-Detection-using-BERT

# Tunisian Dialect Toxicity Detection using BERT

This repository contains code for detecting toxicity in Tunisian dialect using a fine-tuned BERT (Bidirectional Encoder Representations from Transformers) model. The project involves data preprocessing, model training, and deploying the model using a Gradio interface.

## Table of Contents

- [Description](#description)
- [Model Training](#model-training)
- [Model Deployment](#model-deployment)
- [Gradio Interface](#gradio-interface)
- [References](#references)

## Description

The purpose of this project is to detect toxic comments in the Tunisian dialect using a machine learning approach. By fine-tuning a BERT model, we aim to leverage its powerful natural language understanding capabilities to classify text as toxic or non-toxic. The project covers all stages from data preprocessing and model training to deploying the model in an interactive web application using Gradio.

## Model Training

The training process involves several key steps:
1. **Data Preparation:** The dataset, which contains comments labeled as toxic or non-toxic, is preprocessed and prepared for training.
2. **Model Fine-Tuning:** A pre-trained BERT model is fine-tuned on the prepared dataset. This process adjusts the model parameters to better fit the specific characteristics of Tunisian dialect toxicity.
3. **Evaluation:** The model's performan
